{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67904f55-ec83-4d97-aa05-bba971265bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/02 13:56:34 WARN  SparkSession:72 Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://a435bd4c7c73:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://sales-spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc448589370>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"Optimizing Shuffles\")\n",
    "    .master(\"spark://sales-spark-master:7077\")\n",
    "    .config(\"spark.cores.max\", 12)\n",
    "    .config(\"spark.executor.cores\", 4)\n",
    "    .config(\"spark.executor.memory\", \"512M\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "578a9878-d980-4cee-9ef9-4bd7fb0a3007",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Spark defaultParallelism\n",
    "\n",
    "spark.sparkContext.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d26dd8-c7d8-4848-9d52-ce283419dcee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Disable AQE and Broadcast join\n",
    "\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", False)\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", False)\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bb7faf5-1a45-498a-8569-a16790fe06be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read EMP CSV file with 10M records\n",
    "\n",
    "_schema = \"first_name string, last_name string, job_title string, dob string, email string, phone string, salary double, department_id int\"\n",
    "\n",
    "emp = spark.read.format(\"csv\").schema(_schema).option(\"header\", True).load(\"/opt/spark/datasets/input/employee_records.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70a5b553-69a6-47b0-bd58-a91b59135cff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find out avg salary as per dept\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "emp_avg = emp.groupBy(\"department_id\").agg(avg(\"salary\").alias(\"avg_sal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b982be3b-ae76-467d-9393-81e0dedfb847",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/02 13:56:52 WARN  DataSourceV2RelationDatasetExtractor:162 Couldn't find identifier for dataset in plan RelationV2[]  noop-table\n",
      "\n",
      "25/05/02 13:56:52 WARN  DataSourceV2RelationDatasetExtractor:189 Catalog Cannot extract dataset from relation=RelationV2[]  noop-table relationClass=org.apache.spark.sql.execution.datasources.v2.DataSourceV2Relation is unsupported\n",
      "25/05/02 13:56:52 ERROR EventEmitter:77 Could not emit lineage w/ exception\n",
      "io.openlineage.client.OpenLineageClientException: io.openlineage.spark.shaded.org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:5000 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:208)\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:181)\n",
      "\tat io.openlineage.client.OpenLineageClient.lambda$emit$0(OpenLineageClient.java:86)\n",
      "\tat io.micrometer.core.instrument.composite.CompositeTimer.record(CompositeTimer.java:141)\n",
      "\tat io.openlineage.client.OpenLineageClient.emit(OpenLineageClient.java:86)\n",
      "\tat io.openlineage.spark.agent.EventEmitter.emit(EventEmitter.java:66)\n",
      "\tat io.openlineage.spark.agent.lifecycle.SparkSQLExecutionContext.start(SparkSQLExecutionContext.java:112)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.lambda$sparkSQLExecStart$0(OpenLineageSparkListener.java:135)\n",
      "\tat io.openlineage.client.circuitBreaker.NoOpCircuitBreaker.run(NoOpCircuitBreaker.java:27)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.lambda$sparkSQLExecStart$1(OpenLineageSparkListener.java:132)\n",
      "\tat java.base/java.util.Optional.ifPresent(Optional.java:178)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.sparkSQLExecStart(OpenLineageSparkListener.java:129)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.onOtherEvent(OpenLineageSparkListener.java:118)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent(SparkListenerBus.scala:100)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent$(SparkListenerBus.scala:28)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll(ListenerBus.scala:117)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll$(ListenerBus.scala:101)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.super$postToAll(AsyncEventQueue.scala:105)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.$anonfun$dispatch$1(AsyncEventQueue.scala:105)\n",
      "\tat scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:100)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.$anonfun$run$1(AsyncEventQueue.scala:96)\n",
      "\tat org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1356)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.run(AsyncEventQueue.scala:96)\n",
      "Caused by: io.openlineage.spark.shaded.org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:5000 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused\n",
      "\tat java.base/sun.nio.ch.Net.pollConnect(Native Method)\n",
      "\tat java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:547)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:602)\n",
      "\tat java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)\n",
      "\tat java.base/java.net.Socket.connect(Socket.java:633)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:216)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:490)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:164)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:174)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:144)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:150)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:110)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:183)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:245)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:188)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:162)\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:201)\n",
      "\t... 26 more\n",
      "25/05/02 13:56:53 WARN  DataSourceV2RelationDatasetExtractor:162 Couldn't find identifier for dataset in plan RelationV2[]  noop-table\n",
      "\n",
      "25/05/02 13:56:53 WARN  DataSourceV2RelationDatasetExtractor:189 Catalog Cannot extract dataset from relation=RelationV2[]  noop-table relationClass=org.apache.spark.sql.execution.datasources.v2.DataSourceV2Relation is unsupported\n",
      "25/05/02 13:56:53 ERROR EventEmitter:77 Could not emit lineage w/ exception\n",
      "io.openlineage.client.OpenLineageClientException: io.openlineage.spark.shaded.org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:5000 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:208)\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:181)\n",
      "\tat io.openlineage.client.OpenLineageClient.lambda$emit$0(OpenLineageClient.java:86)\n",
      "\tat io.micrometer.core.instrument.composite.CompositeTimer.record(CompositeTimer.java:141)\n",
      "\tat io.openlineage.client.OpenLineageClient.emit(OpenLineageClient.java:86)\n",
      "\tat io.openlineage.spark.agent.EventEmitter.emit(EventEmitter.java:66)\n",
      "\tat io.openlineage.spark.agent.lifecycle.SparkSQLExecutionContext.start(SparkSQLExecutionContext.java:275)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.lambda$onJobStart$13(OpenLineageSparkListener.java:219)\n",
      "\tat io.openlineage.client.circuitBreaker.NoOpCircuitBreaker.run(NoOpCircuitBreaker.java:27)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.lambda$onJobStart$14(OpenLineageSparkListener.java:217)\n",
      "\tat java.base/java.util.Optional.ifPresent(Optional.java:178)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.onJobStart(OpenLineageSparkListener.java:213)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent(SparkListenerBus.scala:37)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent$(SparkListenerBus.scala:28)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll(ListenerBus.scala:117)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll$(ListenerBus.scala:101)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.super$postToAll(AsyncEventQueue.scala:105)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.$anonfun$dispatch$1(AsyncEventQueue.scala:105)\n",
      "\tat scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:100)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.$anonfun$run$1(AsyncEventQueue.scala:96)\n",
      "\tat org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1356)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.run(AsyncEventQueue.scala:96)\n",
      "Caused by: io.openlineage.spark.shaded.org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:5000 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused\n",
      "\tat java.base/sun.nio.ch.Net.pollConnect(Native Method)\n",
      "\tat java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:547)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:602)\n",
      "\tat java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)\n",
      "\tat java.base/java.net.Socket.connect(Socket.java:633)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:216)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:490)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:164)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:174)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:144)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:150)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:110)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:183)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:245)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:188)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:162)\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:201)\n",
      "\t... 25 more\n",
      "25/05/02 13:56:58 WARN  DataSourceV2RelationDatasetExtractor:162 Couldn't find identifier for dataset in plan RelationV2[]  noop-table\n",
      "\n",
      "25/05/02 13:56:58 WARN  DataSourceV2RelationDatasetExtractor:189 Catalog Cannot extract dataset from relation=RelationV2[]  noop-table relationClass=org.apache.spark.sql.execution.datasources.v2.DataSourceV2Relation is unsupported\n",
      "25/05/02 13:56:58 ERROR EventEmitter:77 Could not emit lineage w/ exception\n",
      "io.openlineage.client.OpenLineageClientException: io.openlineage.spark.shaded.org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:5000 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:208)\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:181)\n",
      "\tat io.openlineage.client.OpenLineageClient.lambda$emit$0(OpenLineageClient.java:86)\n",
      "\tat io.micrometer.core.instrument.composite.CompositeTimer.record(CompositeTimer.java:141)\n",
      "\tat io.openlineage.client.OpenLineageClient.emit(OpenLineageClient.java:86)\n",
      "\tat io.openlineage.spark.agent.EventEmitter.emit(EventEmitter.java:66)\n",
      "\tat io.openlineage.spark.agent.lifecycle.SparkSQLExecutionContext.end(SparkSQLExecutionContext.java:324)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.lambda$onJobEnd$15(OpenLineageSparkListener.java:241)\n",
      "\tat io.openlineage.client.circuitBreaker.NoOpCircuitBreaker.run(NoOpCircuitBreaker.java:27)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.onJobEnd(OpenLineageSparkListener.java:238)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent(SparkListenerBus.scala:39)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent$(SparkListenerBus.scala:28)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll(ListenerBus.scala:117)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll$(ListenerBus.scala:101)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.super$postToAll(AsyncEventQueue.scala:105)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.$anonfun$dispatch$1(AsyncEventQueue.scala:105)\n",
      "\tat scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:100)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.$anonfun$run$1(AsyncEventQueue.scala:96)\n",
      "\tat org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1356)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.run(AsyncEventQueue.scala:96)\n",
      "Caused by: io.openlineage.spark.shaded.org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:5000 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused\n",
      "\tat java.base/sun.nio.ch.Net.pollConnect(Native Method)\n",
      "\tat java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:547)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:602)\n",
      "\tat java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)\n",
      "\tat java.base/java.net.Socket.connect(Socket.java:633)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:216)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:490)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:164)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:174)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:144)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:150)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:110)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:183)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:245)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:188)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:162)\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:201)\n",
      "\t... 23 more\n",
      "25/05/02 13:56:58 WARN  DatasetVersionDatasetFacetUtils:34 Couldn't find identifier for dataset in plan RelationV2[]  noop-table\n",
      "\n",
      "25/05/02 13:56:58 WARN  DataSourceV2RelationDatasetExtractor:162 Couldn't find identifier for dataset in plan RelationV2[]  noop-table\n",
      "\n",
      "25/05/02 13:56:58 WARN  DataSourceV2RelationDatasetExtractor:189 Catalog Cannot extract dataset from relation=RelationV2[]  noop-table relationClass=org.apache.spark.sql.execution.datasources.v2.DataSourceV2Relation is unsupported\n",
      "25/05/02 13:56:58 ERROR EventEmitter:77 Could not emit lineage w/ exception\n",
      "io.openlineage.client.OpenLineageClientException: io.openlineage.spark.shaded.org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:5000 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:208)\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:181)\n",
      "\tat io.openlineage.client.OpenLineageClient.lambda$emit$0(OpenLineageClient.java:86)\n",
      "\tat io.micrometer.core.instrument.composite.CompositeTimer.record(CompositeTimer.java:141)\n",
      "\tat io.openlineage.client.OpenLineageClient.emit(OpenLineageClient.java:86)\n",
      "\tat io.openlineage.spark.agent.EventEmitter.emit(EventEmitter.java:66)\n",
      "\tat io.openlineage.spark.agent.lifecycle.SparkSQLExecutionContext.end(SparkSQLExecutionContext.java:161)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.lambda$sparkSQLExecEnd$2(OpenLineageSparkListener.java:150)\n",
      "\tat io.openlineage.client.circuitBreaker.NoOpCircuitBreaker.run(NoOpCircuitBreaker.java:27)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.sparkSQLExecEnd(OpenLineageSparkListener.java:147)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.onOtherEvent(OpenLineageSparkListener.java:122)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent(SparkListenerBus.scala:100)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent$(SparkListenerBus.scala:28)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll(ListenerBus.scala:117)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll$(ListenerBus.scala:101)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.super$postToAll(AsyncEventQueue.scala:105)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.$anonfun$dispatch$1(AsyncEventQueue.scala:105)\n",
      "\tat scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:100)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.$anonfun$run$1(AsyncEventQueue.scala:96)\n",
      "\tat org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1356)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.run(AsyncEventQueue.scala:96)\n",
      "Caused by: io.openlineage.spark.shaded.org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:5000 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused\n",
      "\tat java.base/sun.nio.ch.Net.pollConnect(Native Method)\n",
      "\tat java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:547)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:602)\n",
      "\tat java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)\n",
      "\tat java.base/java.net.Socket.connect(Socket.java:633)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:216)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:490)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:164)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:174)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:144)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:150)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:110)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:183)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:245)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:188)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:162)\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:201)\n",
      "\t... 24 more\n"
     ]
    }
   ],
   "source": [
    "# Write data for performance Benchmarking\n",
    "\n",
    "emp_avg.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6461ffb0-1438-4e3a-a1c3-9abe96371fab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Spark Shuffle Partition setting\n",
    "\n",
    "spark.conf.get(\"spark.sql.shuffle.partitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4968a5d4-817d-4eeb-9457-20d7a578fb51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8142b4aa-5e8d-49e0-b478-79959229c611",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/02 13:57:11 ERROR EventEmitter:77 Could not emit lineage w/ exception\n",
      "io.openlineage.client.OpenLineageClientException: io.openlineage.spark.shaded.org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:5000 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:208)\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:181)\n",
      "\tat io.openlineage.client.OpenLineageClient.lambda$emit$0(OpenLineageClient.java:86)\n",
      "\tat io.micrometer.core.instrument.composite.CompositeTimer.record(CompositeTimer.java:141)\n",
      "\tat io.openlineage.client.OpenLineageClient.emit(OpenLineageClient.java:86)\n",
      "\tat io.openlineage.spark.agent.EventEmitter.emit(EventEmitter.java:66)\n",
      "\tat io.openlineage.spark.agent.lifecycle.SparkSQLExecutionContext.start(SparkSQLExecutionContext.java:112)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.lambda$sparkSQLExecStart$0(OpenLineageSparkListener.java:135)\n",
      "\tat io.openlineage.client.circuitBreaker.NoOpCircuitBreaker.run(NoOpCircuitBreaker.java:27)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.lambda$sparkSQLExecStart$1(OpenLineageSparkListener.java:132)\n",
      "\tat java.base/java.util.Optional.ifPresent(Optional.java:178)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.sparkSQLExecStart(OpenLineageSparkListener.java:129)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.onOtherEvent(OpenLineageSparkListener.java:118)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent(SparkListenerBus.scala:100)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent$(SparkListenerBus.scala:28)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll(ListenerBus.scala:117)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll$(ListenerBus.scala:101)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.super$postToAll(AsyncEventQueue.scala:105)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.$anonfun$dispatch$1(AsyncEventQueue.scala:105)\n",
      "\tat scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:100)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.$anonfun$run$1(AsyncEventQueue.scala:96)\n",
      "\tat org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1356)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.run(AsyncEventQueue.scala:96)\n",
      "Caused by: io.openlineage.spark.shaded.org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:5000 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused\n",
      "\tat java.base/sun.nio.ch.Net.pollConnect(Native Method)\n",
      "\tat java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:547)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:602)\n",
      "\tat java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)\n",
      "\tat java.base/java.net.Socket.connect(Socket.java:633)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:216)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:490)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:164)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:174)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:144)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:150)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:110)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:183)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:245)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:188)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:162)\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:201)\n",
      "\t... 26 more\n",
      "25/05/02 13:57:11 ERROR EventEmitter:77 Could not emit lineage w/ exception\n",
      "io.openlineage.client.OpenLineageClientException: io.openlineage.spark.shaded.org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:5000 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:208)\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:181)\n",
      "\tat io.openlineage.client.OpenLineageClient.lambda$emit$0(OpenLineageClient.java:86)\n",
      "\tat io.micrometer.core.instrument.composite.CompositeTimer.record(CompositeTimer.java:141)\n",
      "\tat io.openlineage.client.OpenLineageClient.emit(OpenLineageClient.java:86)\n",
      "\tat io.openlineage.spark.agent.EventEmitter.emit(EventEmitter.java:66)\n",
      "\tat io.openlineage.spark.agent.lifecycle.SparkSQLExecutionContext.start(SparkSQLExecutionContext.java:275)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.lambda$onJobStart$13(OpenLineageSparkListener.java:219)\n",
      "\tat io.openlineage.client.circuitBreaker.NoOpCircuitBreaker.run(NoOpCircuitBreaker.java:27)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.lambda$onJobStart$14(OpenLineageSparkListener.java:217)\n",
      "\tat java.base/java.util.Optional.ifPresent(Optional.java:178)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.onJobStart(OpenLineageSparkListener.java:213)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent(SparkListenerBus.scala:37)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent$(SparkListenerBus.scala:28)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll(ListenerBus.scala:117)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll$(ListenerBus.scala:101)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.super$postToAll(AsyncEventQueue.scala:105)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.$anonfun$dispatch$1(AsyncEventQueue.scala:105)\n",
      "\tat scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:100)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.$anonfun$run$1(AsyncEventQueue.scala:96)\n",
      "\tat org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1356)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.run(AsyncEventQueue.scala:96)\n",
      "Caused by: io.openlineage.spark.shaded.org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:5000 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused\n",
      "\tat java.base/sun.nio.ch.Net.pollConnect(Native Method)\n",
      "\tat java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:547)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:602)\n",
      "\tat java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)\n",
      "\tat java.base/java.net.Socket.connect(Socket.java:633)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:216)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:490)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:164)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:174)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:144)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:150)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:110)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:183)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:245)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:188)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:162)\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:201)\n",
      "\t... 25 more\n",
      "25/05/02 13:57:11 ERROR EventEmitter:77 Could not emit lineage w/ exception\n",
      "io.openlineage.client.OpenLineageClientException: io.openlineage.spark.shaded.org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:5000 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:208)\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:181)\n",
      "\tat io.openlineage.client.OpenLineageClient.lambda$emit$0(OpenLineageClient.java:86)\n",
      "\tat io.micrometer.core.instrument.composite.CompositeTimer.record(CompositeTimer.java:141)\n",
      "\tat io.openlineage.client.OpenLineageClient.emit(OpenLineageClient.java:86)\n",
      "\tat io.openlineage.spark.agent.EventEmitter.emit(EventEmitter.java:66)\n",
      "\tat io.openlineage.spark.agent.lifecycle.SparkSQLExecutionContext.end(SparkSQLExecutionContext.java:324)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.lambda$onJobEnd$15(OpenLineageSparkListener.java:241)\n",
      "\tat io.openlineage.client.circuitBreaker.NoOpCircuitBreaker.run(NoOpCircuitBreaker.java:27)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.onJobEnd(OpenLineageSparkListener.java:238)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent(SparkListenerBus.scala:39)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent$(SparkListenerBus.scala:28)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll(ListenerBus.scala:117)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll$(ListenerBus.scala:101)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.super$postToAll(AsyncEventQueue.scala:105)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.$anonfun$dispatch$1(AsyncEventQueue.scala:105)\n",
      "\tat scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:100)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.$anonfun$run$1(AsyncEventQueue.scala:96)\n",
      "\tat org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1356)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.run(AsyncEventQueue.scala:96)\n",
      "Caused by: io.openlineage.spark.shaded.org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:5000 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused\n",
      "\tat java.base/sun.nio.ch.Net.pollConnect(Native Method)\n",
      "\tat java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:547)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:602)\n",
      "\tat java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)\n",
      "\tat java.base/java.net.Socket.connect(Socket.java:633)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:216)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:490)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:164)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:174)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:144)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:150)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:110)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:183)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:245)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:188)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:162)\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:201)\n",
      "\t... 23 more\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+----------+--------------------+--------------------+--------+-------------+------------+\n",
      "|first_name| last_name|           job_title|       dob|               email|               phone|  salary|department_id|partition_id|\n",
      "+----------+----------+--------------------+----------+--------------------+--------------------+--------+-------------+------------+\n",
      "|   Richard|  Morrison|Public relations ...|1973-05-05|melissagarcia@exa...|       (699)525-4827|512653.0|            8|           0|\n",
      "|     Bobby|  Mccarthy|   Barrister's clerk|1974-04-25|   llara@example.net|  (750)846-1602x7458|999836.0|            7|           0|\n",
      "|    Dennis|    Norman|Land/geomatics su...|1990-06-24| jturner@example.net|    873.820.0518x825|131900.0|           10|           0|\n",
      "|      John|    Monroe|        Retail buyer|1968-06-16|  erik33@example.net|    820-813-0557x624|485506.0|            1|           0|\n",
      "|  Michelle|   Elliott|      Air cabin crew|1975-03-31|tiffanyjohnston@e...|       (705)900-5337|604738.0|            8|           0|\n",
      "|    Ashley|   Montoya|        Cartographer|1976-01-16|patrickalexandra@...|        211.440.5466|483339.0|            6|           0|\n",
      "| Nathaniel|     Smith|     Quality manager|1985-06-28|  lori44@example.net|        936-403-3179|419644.0|            7|           0|\n",
      "|     Faith|  Cummings|Industrial/produc...|1978-07-01| ygordon@example.org|       (889)246-5588|205939.0|            7|           0|\n",
      "|  Margaret|    Sutton|Administrator, ed...|1975-08-16| diana44@example.net|001-647-530-5036x...|671167.0|            8|           0|\n",
      "|      Mary|    Sutton|   Freight forwarder|1979-12-28|  ryan36@example.com|   422.562.7254x3159|993829.0|            7|           0|\n",
      "|      Jake|      King|       Lexicographer|1994-07-11|monica93@example.org|+1-535-652-9715x6...|702101.0|            4|           0|\n",
      "|   Heather|     Haley|         Music tutor|1981-06-01|stephanie65@examp...|   (652)815-7973x298|570960.0|            6|           0|\n",
      "|    Thomas|    Thomas|Chartered managem...|2001-07-17|pwilliams@example...|001-245-848-0028x...|339441.0|            6|           0|\n",
      "|   Leonard|   Carlson|       Art therapist|1990-10-18|gabrielmurray@exa...|          9247590563|469728.0|            8|           0|\n",
      "|      Mark|      Wood|   Market researcher|1963-10-13|nicholas76@exampl...|   311.439.1606x3342|582291.0|            4|           0|\n",
      "|    Tracey|Washington|Travel agency man...|1986-05-07|  mark07@example.com|    001-912-206-6456|146456.0|            4|           0|\n",
      "|   Rachael| Rodriguez|         Media buyer|1966-12-02|griffinmary@examp...| +1-791-344-7586x548|544732.0|            1|           0|\n",
      "|      Tara|       Liu|   Financial adviser|1998-10-12|alexandraobrien@e...|        216.696.6061|399503.0|            3|           0|\n",
      "|       Ana|    Joseph|      Retail manager|1995-01-10|  rmorse@example.org|  (726)363-7526x9965|761988.0|           10|           0|\n",
      "|   Richard|      Hall|Engineer, civil (...|1967-03-02|brandoncardenas@e...| (964)451-9007x22496|660659.0|            4|           0|\n",
      "+----------+----------+--------------------+----------+--------------------+--------------------+--------+-------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/02 13:57:12 ERROR EventEmitter:77 Could not emit lineage w/ exception\n",
      "io.openlineage.client.OpenLineageClientException: io.openlineage.spark.shaded.org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:5000 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:208)\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:181)\n",
      "\tat io.openlineage.client.OpenLineageClient.lambda$emit$0(OpenLineageClient.java:86)\n",
      "\tat io.micrometer.core.instrument.composite.CompositeTimer.record(CompositeTimer.java:141)\n",
      "\tat io.openlineage.client.OpenLineageClient.emit(OpenLineageClient.java:86)\n",
      "\tat io.openlineage.spark.agent.EventEmitter.emit(EventEmitter.java:66)\n",
      "\tat io.openlineage.spark.agent.lifecycle.SparkSQLExecutionContext.end(SparkSQLExecutionContext.java:161)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.lambda$sparkSQLExecEnd$2(OpenLineageSparkListener.java:150)\n",
      "\tat io.openlineage.client.circuitBreaker.NoOpCircuitBreaker.run(NoOpCircuitBreaker.java:27)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.sparkSQLExecEnd(OpenLineageSparkListener.java:147)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.onOtherEvent(OpenLineageSparkListener.java:122)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent(SparkListenerBus.scala:100)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent$(SparkListenerBus.scala:28)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll(ListenerBus.scala:117)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll$(ListenerBus.scala:101)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.super$postToAll(AsyncEventQueue.scala:105)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.$anonfun$dispatch$1(AsyncEventQueue.scala:105)\n",
      "\tat scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:100)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.$anonfun$run$1(AsyncEventQueue.scala:96)\n",
      "\tat org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1356)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.run(AsyncEventQueue.scala:96)\n",
      "Caused by: io.openlineage.spark.shaded.org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:5000 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused\n",
      "\tat java.base/sun.nio.ch.Net.pollConnect(Native Method)\n",
      "\tat java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:547)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:602)\n",
      "\tat java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)\n",
      "\tat java.base/java.net.Socket.connect(Socket.java:633)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:216)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:490)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:164)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:174)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:144)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:150)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:110)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:183)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:245)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:188)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:162)\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:201)\n",
      "\t... 24 more\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import spark_partition_id\n",
    "\n",
    "emp.withColumn(\"partition_id\", spark_partition_id()).where(\"partition_id = 0\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40552990-399e-42d9-a0c9-7c920c922b71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_NOT_FOUND] Path does not exist: file:/opt/spark/datasets/input/emp_partitioned.csv.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAnalysisException\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Read the partitioned data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m emp_part = \u001b[43mspark\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_schema\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mheader\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/opt/spark/datasets/input/emp_partitioned.csv/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/pyspark/sql/readwriter.py:307\u001b[39m, in \u001b[36mDataFrameReader.load\u001b[39m\u001b[34m(self, path, format, schema, **options)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;28mself\u001b[39m.options(**options)\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jreader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) != \u001b[38;5;28mlist\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    181\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    183\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mAnalysisException\u001b[39m: [PATH_NOT_FOUND] Path does not exist: file:/opt/spark/datasets/input/emp_partitioned.csv."
     ]
    }
   ],
   "source": [
    "# Read the partitioned data\n",
    "\n",
    "emp_part = spark.read.format(\"csv\").schema(_schema).option(\"header\", True).load(\"/opt/spark/datasets/input/emp_partitioned.csv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "707125af-139d-411e-8bc5-ce39dbfd8f36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emp_part' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m emp_avg = \u001b[43memp_part\u001b[49m.groupBy(\u001b[33m\"\u001b[39m\u001b[33mdepartment_id\u001b[39m\u001b[33m\"\u001b[39m).agg(avg(\u001b[33m\"\u001b[39m\u001b[33msalary\u001b[39m\u001b[33m\"\u001b[39m).alias(\u001b[33m\"\u001b[39m\u001b[33mavg_sal\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'emp_part' is not defined"
     ]
    }
   ],
   "source": [
    "emp_avg = emp_part.groupBy(\"department_id\").agg(avg(\"salary\").alias(\"avg_sal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "650c8a41-a9eb-4fb1-b337-66ec689b0a0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emp_avg.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8740183-1899-468f-bd67-af5fdb91b748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/02 13:58:17 ERROR EventEmitter:77 Could not emit lineage w/ exception\n",
      "io.openlineage.client.OpenLineageClientException: io.openlineage.spark.shaded.org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:5000 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:208)\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:181)\n",
      "\tat io.openlineage.client.OpenLineageClient.lambda$emit$0(OpenLineageClient.java:86)\n",
      "\tat io.micrometer.core.instrument.composite.CompositeTimer.record(CompositeTimer.java:141)\n",
      "\tat io.openlineage.client.OpenLineageClient.emit(OpenLineageClient.java:86)\n",
      "\tat io.openlineage.spark.agent.EventEmitter.emit(EventEmitter.java:66)\n",
      "\tat io.openlineage.spark.agent.lifecycle.SparkApplicationExecutionContext.end(SparkApplicationExecutionContext.java:129)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.lambda$onApplicationEnd$19(OpenLineageSparkListener.java:310)\n",
      "\tat io.openlineage.client.circuitBreaker.NoOpCircuitBreaker.run(NoOpCircuitBreaker.java:27)\n",
      "\tat io.openlineage.spark.agent.OpenLineageSparkListener.onApplicationEnd(OpenLineageSparkListener.java:308)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent(SparkListenerBus.scala:57)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent$(SparkListenerBus.scala:28)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll(ListenerBus.scala:117)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll$(ListenerBus.scala:101)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.super$postToAll(AsyncEventQueue.scala:105)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.$anonfun$dispatch$1(AsyncEventQueue.scala:105)\n",
      "\tat scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:100)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.$anonfun$run$1(AsyncEventQueue.scala:96)\n",
      "\tat org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1356)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.run(AsyncEventQueue.scala:96)\n",
      "Caused by: io.openlineage.spark.shaded.org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:5000 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused\n",
      "\tat java.base/sun.nio.ch.Net.pollConnect(Native Method)\n",
      "\tat java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:547)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:602)\n",
      "\tat java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)\n",
      "\tat java.base/java.net.Socket.connect(Socket.java:633)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:216)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:490)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:164)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:174)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:144)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:150)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:110)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:183)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:245)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:188)\n",
      "\tat io.openlineage.spark.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:162)\n",
      "\tat io.openlineage.client.transports.HttpTransport.emit(HttpTransport.java:201)\n",
      "\t... 23 more\n"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
